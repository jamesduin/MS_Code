\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand*{\memsetcounter}[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {chapter}{Contents}{v}{section*.1}}
\citation{mitchell}
\citation{scikit-learn}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {1}Introduction}{1}{chapter.1}}
\newlabel{chap:aenied}{{\M@TitleReference {1}{Introduction}}{1}{Introduction}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Machine Learning}{1}{section.1.1}}
\@writefile{brf}{\backcite{mitchell}{{1}{1.1}{section.1.1}}}
\@writefile{brf}{\backcite{scikit-learn}{{1}{1.1}{section.1.1}}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Hierarchical Bioinformatics Data Set}{1}{section.1.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces The protein dataset is labeled according to where it originates in the cell. At the root is “mitochondrion”, then there is the sub level labels for if its native to the mitochondria or if it has a separate target compartment specification. The complete tree along with the number of instances belonging to the each label is included in this figure.\relax }}{2}{figure.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:Mitotree}{{\M@TitleReference {1.1}{The protein dataset is labeled according to where it originates in the cell. At the root is “mitochondrion”, then there is the sub level labels for if its native to the mitochondria or if it has a separate target compartment specification. The complete tree along with the number of instances belonging to the each label is included in this figure.\relax }}{2}{The protein dataset is labeled according to where it originates in the cell. At the root is “mitochondrion”, then there is the sub level labels for if its native to the mitochondria or if it has a separate target compartment specification. The complete tree along with the number of instances belonging to the each label is included in this figure.\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Coarse Grained vs Fine Grained Trade Off}{2}{section.1.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Demonstration of a dataset that would benefit from multiple fine grained learners for each circle type. In order for the coarse grain learner to have high recall, precision must be scarified and a large amount of false positives returned. By combining fine grained classifiers the same level of recall can be achieved with a higher level of precision because none of the false positive diamonds will be returned\relax }}{3}{figure.caption.3}}
\newlabel{fig:union}{{\M@TitleReference {1.2}{Demonstration of a dataset that would benefit from multiple fine grained learners for each circle type. In order for the coarse grain learner to have high recall, precision must be scarified and a large amount of false positives returned. By combining fine grained classifiers the same level of recall can be achieved with a higher level of precision because none of the false positive diamonds will be returned\relax }}{3}{Demonstration of a dataset that would benefit from multiple fine grained learners for each circle type. In order for the coarse grain learner to have high recall, precision must be scarified and a large amount of false positives returned. By combining fine grained classifiers the same level of recall can be achieved with a higher level of precision because none of the false positive diamonds will be returned\relax }{figure.caption.3}{}}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {2}Background and Related Work}{4}{chapter.2}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Active Learning}{4}{section.2.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Hierarchical Active Learning}{5}{section.2.2}}
\newlabel{fig:AL2}{{\M@TitleReference {\caption@xref {fig:AL2}{ on input line 268}}{Hierarchical Active Learning}}{5}{Hierarchical Active Learning}{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Diagram of HAL approach\relax }}{5}{figure.caption.4}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Application to Dispatch Dataset}{5}{section.2.3}}
\newlabel{fig:draft-richmond}{{\M@TitleReference {\caption@xref {fig:draft-richmond}{ on input line 294}}{Application to Dispatch Dataset}}{6}{Application to Dispatch Dataset}{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Application of HAL demonstrating the benefit of Actively selecting the type of labels to purchase for instances rather than randomly selecting labels to purchase, as in the Passive curves.\relax }}{6}{figure.caption.5}}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {3}Experimental Setup}{7}{chapter.3}}
\newlabel{chap:math}{{\M@TitleReference {3}{Experimental Setup}}{7}{Experimental Setup}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Training and Testing Coarse Grain and Fine Grain Classifiers}{7}{section.3.1}}
\newlabel{tab:ClassesAll}{{\M@TitleReference {3.1a}{Classes\relax }}{8}{Classes\relax }{table.caption.6}{}}
\newlabel{sub@tab:ClassesAll}{{\M@TitleReference {a}{Classes\relax }}{8}{Classes\relax }{table.caption.6}{}}
\newlabel{tab:partitions}{{\M@TitleReference {3.1b}{Folds\relax }}{8}{Folds\relax }{table.caption.6}{}}
\newlabel{sub@tab:partitions}{{\M@TitleReference {b}{Folds\relax }}{8}{Folds\relax }{table.caption.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces This dataset contains 20098 instances total with 449 features each. An example partitioning is shown, some classes like 1 and 5 contain only 1-2 instances in a given test set. Note there is a heavy class imbalance with approx. 20 negative instances for each positve instance.\relax }}{8}{table.caption.6}}
\newlabel{tab:dataset}{{\M@TitleReference {3.1}{This dataset contains 20098 instances total with 449 features each. An example partitioning is shown, some classes like 1 and 5 contain only 1-2 instances in a given test set. Note there is a heavy class imbalance with approx. 20 negative instances for each positve instance.\relax }}{8}{This dataset contains 20098 instances total with 449 features each. An example partitioning is shown, some classes like 1 and 5 contain only 1-2 instances in a given test set. Note there is a heavy class imbalance with approx. 20 negative instances for each positve instance.\relax }{table.caption.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces Example of totals for the Train and Test corresponding to when the first fold is held out to be the test set.\relax }}{8}{table.caption.7}}
\newlabel{tab:TrainTest}{{\M@TitleReference {3.2}{Example of totals for the Train and Test corresponding to when the first fold is held out to be the test set.\relax }}{8}{Example of totals for the Train and Test corresponding to when the first fold is held out to be the test set.\relax }{table.caption.7}{}}
\citation{scikit-learn}
\newlabel{tab:ClassesSub}{{\M@TitleReference {3.3a}{Classes Subset\relax }}{9}{Classes Subset\relax }{table.caption.8}{}}
\newlabel{sub@tab:ClassesSub}{{\M@TitleReference {a}{Classes Subset\relax }}{9}{Classes Subset\relax }{table.caption.8}{}}
\newlabel{tab:PartitionsSubset}{{\M@TitleReference {3.3b}{Folds Subset\relax }}{9}{Folds Subset\relax }{table.caption.8}{}}
\newlabel{sub@tab:PartitionsSubset}{{\M@TitleReference {b}{Folds Subset\relax }}{9}{Folds Subset\relax }{table.caption.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.3}{\ignorespaces The subset of instances used for tuning classifier paramters contains approximately $1/5^{th}$ and retains all postive instances.\relax }}{9}{table.caption.8}}
\newlabel{tab:subset}{{\M@TitleReference {3.3}{The subset of instances used for tuning classifier paramters contains approximately $1/5^{th}$ and retains all postive instances.\relax }}{9}{The subset of instances used for tuning classifier paramters contains approximately $1/5^{th}$ and retains all postive instances.\relax }{table.caption.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.4}{\ignorespaces Example totals for the train and test set for the subset of data. The subset of data is used for the majority of the parameter search.\relax }}{9}{table.caption.9}}
\newlabel{tab:subTrainTest}{{\M@TitleReference {3.4}{Example totals for the train and test set for the subset of data. The subset of data is used for the majority of the parameter search.\relax }}{9}{Example totals for the train and test set for the subset of data. The subset of data is used for the majority of the parameter search.\relax }{table.caption.9}{}}
\@writefile{brf}{\backcite{scikit-learn}{{9}{3.1}{table.caption.9}}}
\citation{scikit-learn}
\@writefile{lot}{\contentsline {table}{\numberline {3.5}{\ignorespaces SVMDef result stats\relax }}{10}{table.caption.10}}
\newlabel{tab:SVMDefResStats}{{\M@TitleReference {3.5}{SVMDef result stats\relax }}{10}{SVMDef result stats\relax }{table.caption.10}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.6}{\ignorespaces SVMDef conf matrix\relax }}{10}{table.caption.11}}
\newlabel{tab:SVMDefConfMat}{{\M@TitleReference {3.6}{SVMDef conf matrix\relax }}{10}{SVMDef conf matrix\relax }{table.caption.11}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.7}{\ignorespaces SVMDef\relax }}{10}{table.caption.12}}
\newlabel{tab:SVMDef}{{\M@TitleReference {3.7}{SVMDef\relax }}{10}{SVMDef\relax }{table.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Varied SVM Scaling Methods}{10}{subsection.3.1.1}}
\@writefile{brf}{\backcite{scikit-learn}{{10}{3.1.1}{subsection.3.1.1}}}
\@writefile{lot}{\contentsline {table}{\numberline {3.8}{\ignorespaces SVMMinMax\relax }}{10}{table.caption.13}}
\newlabel{tab:SVMMinMax}{{\M@TitleReference {3.8}{SVMMinMax\relax }}{10}{SVMMinMax\relax }{table.caption.13}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.9}{\ignorespaces SVMNorm\relax }}{11}{table.caption.14}}
\newlabel{tab:SVMNorm}{{\M@TitleReference {3.9}{SVMNorm\relax }}{11}{SVMNorm\relax }{table.caption.14}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.10}{\ignorespaces SVMStandard\relax }}{11}{table.caption.15}}
\newlabel{tab:SVMStandard}{{\M@TitleReference {3.10}{SVMStandard\relax }}{11}{SVMStandard\relax }{table.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Varied SVM Kernels}{11}{subsection.3.1.2}}
\@writefile{lot}{\contentsline {table}{\numberline {3.11}{\ignorespaces RbfOrig\relax }}{11}{table.caption.16}}
\newlabel{tab:RbfOrig}{{\M@TitleReference {3.11}{RbfOrig\relax }}{11}{RbfOrig\relax }{table.caption.16}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.12}{\ignorespaces Linear\relax }}{11}{table.caption.17}}
\newlabel{tab:Linear}{{\M@TitleReference {3.12}{Linear\relax }}{11}{Linear\relax }{table.caption.17}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.13}{\ignorespaces polyDeg3\relax }}{11}{table.caption.18}}
\newlabel{tab:polyDeg3}{{\M@TitleReference {3.13}{polyDeg3\relax }}{11}{polyDeg3\relax }{table.caption.18}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.14}{\ignorespaces polyDeg6\relax }}{11}{table.caption.19}}
\newlabel{tab:polyDeg6}{{\M@TitleReference {3.14}{polyDeg6\relax }}{11}{polyDeg6\relax }{table.caption.19}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.15}{\ignorespaces sigmoid\relax }}{12}{table.caption.20}}
\newlabel{tab:sigmoid}{{\M@TitleReference {3.15}{sigmoid\relax }}{12}{sigmoid\relax }{table.caption.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Varied SVM Feature Selection}{12}{subsection.3.1.3}}
\@writefile{lot}{\contentsline {table}{\numberline {3.16}{\ignorespaces SVMSel25\relax }}{12}{table.caption.21}}
\newlabel{tab:SVMSel25}{{\M@TitleReference {3.16}{SVMSel25\relax }}{12}{SVMSel25\relax }{table.caption.21}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.17}{\ignorespaces SVMSel50\relax }}{12}{table.caption.22}}
\newlabel{tab:SVMSel50}{{\M@TitleReference {3.17}{SVMSel50\relax }}{12}{SVMSel50\relax }{table.caption.22}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.18}{\ignorespaces SVMSel75\relax }}{12}{table.caption.23}}
\newlabel{tab:SVMSel75}{{\M@TitleReference {3.18}{SVMSel75\relax }}{12}{SVMSel75\relax }{table.caption.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.4}Varied SVM Decision Function Shape}{12}{subsection.3.1.4}}
\@writefile{lot}{\contentsline {table}{\numberline {3.19}{\ignorespaces SVM-ovr\relax }}{12}{table.caption.24}}
\newlabel{tab:SVM-ovr}{{\M@TitleReference {3.19}{SVM-ovr\relax }}{12}{SVM-ovr\relax }{table.caption.24}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.20}{\ignorespaces SVM-ovo\relax }}{13}{table.caption.25}}
\newlabel{tab:SVM-ovo}{{\M@TitleReference {3.20}{SVM-ovo\relax }}{13}{SVM-ovo\relax }{table.caption.25}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.5}Varied Logistic Regression Scaling}{13}{subsection.3.1.5}}
\@writefile{lot}{\contentsline {table}{\numberline {3.21}{\ignorespaces LogRegDef\relax }}{13}{table.caption.26}}
\newlabel{tab:LogRegDef}{{\M@TitleReference {3.21}{LogRegDef\relax }}{13}{LogRegDef\relax }{table.caption.26}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.22}{\ignorespaces LogRegStandard\relax }}{13}{table.caption.27}}
\newlabel{tab:LogRegStandard}{{\M@TitleReference {3.22}{LogRegStandard\relax }}{13}{LogRegStandard\relax }{table.caption.27}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.23}{\ignorespaces LogRegNorm\relax }}{13}{table.caption.28}}
\newlabel{tab:LogRegNorm}{{\M@TitleReference {3.23}{LogRegNorm\relax }}{13}{LogRegNorm\relax }{table.caption.28}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.24}{\ignorespaces LogRegMinMax\relax }}{13}{table.caption.29}}
\newlabel{tab:LogRegMinMax}{{\M@TitleReference {3.24}{LogRegMinMax\relax }}{13}{LogRegMinMax\relax }{table.caption.29}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.6}Varied Logistic Regression Feature Selection}{14}{subsection.3.1.6}}
\@writefile{lot}{\contentsline {table}{\numberline {3.25}{\ignorespaces LogRegSel25\relax }}{14}{table.caption.30}}
\newlabel{tab:LogRegSel25}{{\M@TitleReference {3.25}{LogRegSel25\relax }}{14}{LogRegSel25\relax }{table.caption.30}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.26}{\ignorespaces LogRegSel50\relax }}{14}{table.caption.31}}
\newlabel{tab:LogRegSel50}{{\M@TitleReference {3.26}{LogRegSel50\relax }}{14}{LogRegSel50\relax }{table.caption.31}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.27}{\ignorespaces LogRegSel75\relax }}{14}{table.caption.32}}
\newlabel{tab:LogRegSel75}{{\M@TitleReference {3.27}{LogRegSel75\relax }}{14}{LogRegSel75\relax }{table.caption.32}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.7}Varied Logistic Regression Postive Class Weight and Cost}{14}{subsection.3.1.7}}
\@writefile{lot}{\contentsline {table}{\numberline {3.28}{\ignorespaces LogRegWtOrig-C1\relax }}{14}{table.caption.33}}
\newlabel{tab:LogRegWtOrig-C1}{{\M@TitleReference {3.28}{LogRegWtOrig-C1\relax }}{14}{LogRegWtOrig-C1\relax }{table.caption.33}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.29}{\ignorespaces LogRegWtOrig-Cp1\relax }}{14}{table.caption.34}}
\newlabel{tab:LogRegWtOrig-Cp1}{{\M@TitleReference {3.29}{LogRegWtOrig-Cp1\relax }}{14}{LogRegWtOrig-Cp1\relax }{table.caption.34}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.30}{\ignorespaces LogRegWtOrig-C10\relax }}{14}{table.caption.35}}
\newlabel{tab:LogRegWtOrig-C10}{{\M@TitleReference {3.30}{LogRegWtOrig-C10\relax }}{14}{LogRegWtOrig-C10\relax }{table.caption.35}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.31}{\ignorespaces LogRegWt10-C1\relax }}{15}{table.caption.36}}
\newlabel{tab:LogRegWt10-C1}{{\M@TitleReference {3.31}{LogRegWt10-C1\relax }}{15}{LogRegWt10-C1\relax }{table.caption.36}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.32}{\ignorespaces LogRegWt10-Cp1\relax }}{15}{table.caption.37}}
\newlabel{tab:LogRegWt10-Cp1}{{\M@TitleReference {3.32}{LogRegWt10-Cp1\relax }}{15}{LogRegWt10-Cp1\relax }{table.caption.37}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.33}{\ignorespaces LogRegWt10-C10\relax }}{15}{table.caption.38}}
\newlabel{tab:LogRegWt10-C10}{{\M@TitleReference {3.33}{LogRegWt10-C10\relax }}{15}{LogRegWt10-C10\relax }{table.caption.38}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.34}{\ignorespaces LogRegWt7p5-C1\relax }}{15}{table.caption.39}}
\newlabel{tab:LogRegWt7p5-C1}{{\M@TitleReference {3.34}{LogRegWt7p5-C1\relax }}{15}{LogRegWt7p5-C1\relax }{table.caption.39}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.35}{\ignorespaces LogRegWt7p5-Cp1\relax }}{15}{table.caption.40}}
\newlabel{tab:LogRegWt7p5-Cp1}{{\M@TitleReference {3.35}{LogRegWt7p5-Cp1\relax }}{15}{LogRegWt7p5-Cp1\relax }{table.caption.40}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.36}{\ignorespaces LogRegWt7p5-C10\relax }}{15}{table.caption.41}}
\newlabel{tab:LogRegWt7p5-C10}{{\M@TitleReference {3.36}{LogRegWt7p5-C10\relax }}{15}{LogRegWt7p5-C10\relax }{table.caption.41}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.8}Varied Logistic Regression Tune Fine Class Weights}{16}{subsection.3.1.8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.8.1}Fine Tune Class 1 Weights}{16}{subsubsection.3.1.8.1}}
\@writefile{lot}{\contentsline {table}{\numberline {3.37}{\ignorespaces LogRegCls1-Wt1\relax }}{16}{table.caption.42}}
\newlabel{tab:LogRegCls1-Wt1}{{\M@TitleReference {3.37}{LogRegCls1-Wt1\relax }}{16}{LogRegCls1-Wt1\relax }{table.caption.42}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.38}{\ignorespaces LogRegCls1-Wtp5\relax }}{16}{table.caption.43}}
\newlabel{tab:LogRegCls1-Wtp5}{{\M@TitleReference {3.38}{LogRegCls1-Wtp5\relax }}{16}{LogRegCls1-Wtp5\relax }{table.caption.43}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.39}{\ignorespaces LogRegCls1-Wt3: this won!\relax }}{16}{table.caption.44}}
\newlabel{tab:LogRegCls1-Wt3}{{\M@TitleReference {3.39}{LogRegCls1-Wt3: this won!\relax }}{16}{LogRegCls1-Wt3: this won!\relax }{table.caption.44}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.40}{\ignorespaces LogRegCls1-Wt5\relax }}{16}{table.caption.45}}
\newlabel{tab:LogRegCls1-Wt5}{{\M@TitleReference {3.40}{LogRegCls1-Wt5\relax }}{16}{LogRegCls1-Wt5\relax }{table.caption.45}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.8.2}Fine Tune Class 2 Weights}{16}{subsubsection.3.1.8.2}}
\@writefile{lot}{\contentsline {table}{\numberline {3.41}{\ignorespaces LogRegCls2-Wt1: this won!\relax }}{16}{table.caption.46}}
\newlabel{tab:LogRegCls2-Wt1}{{\M@TitleReference {3.41}{LogRegCls2-Wt1: this won!\relax }}{16}{LogRegCls2-Wt1: this won!\relax }{table.caption.46}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.42}{\ignorespaces LogRegCls2-Wtp5\relax }}{17}{table.caption.47}}
\newlabel{tab:LogRegCls2-Wtp5}{{\M@TitleReference {3.42}{LogRegCls2-Wtp5\relax }}{17}{LogRegCls2-Wtp5\relax }{table.caption.47}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.43}{\ignorespaces LogRegCls2-Wt1p5\relax }}{17}{table.caption.48}}
\newlabel{tab:LogRegCls2-Wt1p5}{{\M@TitleReference {3.43}{LogRegCls2-Wt1p5\relax }}{17}{LogRegCls2-Wt1p5\relax }{table.caption.48}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.8.3}Fine Tune Class 3 Weights}{17}{subsubsection.3.1.8.3}}
\@writefile{lot}{\contentsline {table}{\numberline {3.44}{\ignorespaces LogRegCls3-Wt1: this won!\relax }}{17}{table.caption.49}}
\newlabel{tab:LogRegCls3-Wt1}{{\M@TitleReference {3.44}{LogRegCls3-Wt1: this won!\relax }}{17}{LogRegCls3-Wt1: this won!\relax }{table.caption.49}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.45}{\ignorespaces LogRegCls3-Wtp5\relax }}{17}{table.caption.50}}
\newlabel{tab:LogRegCls3-Wtp5}{{\M@TitleReference {3.45}{LogRegCls3-Wtp5\relax }}{17}{LogRegCls3-Wtp5\relax }{table.caption.50}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.46}{\ignorespaces LogRegCls3-Wt1p5\relax }}{17}{table.caption.51}}
\newlabel{tab:LogRegCls3-Wt1p5}{{\M@TitleReference {3.46}{LogRegCls3-Wt1p5\relax }}{17}{LogRegCls3-Wt1p5\relax }{table.caption.51}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.8.4}Fine Tune Class 4 Weights}{18}{subsubsection.3.1.8.4}}
\@writefile{lot}{\contentsline {table}{\numberline {3.47}{\ignorespaces LogRegCls4-Wt1\relax }}{18}{table.caption.52}}
\newlabel{tab:LogRegCls4-Wt1}{{\M@TitleReference {3.47}{LogRegCls4-Wt1\relax }}{18}{LogRegCls4-Wt1\relax }{table.caption.52}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.48}{\ignorespaces LogRegCls4-Wtp5\relax }}{18}{table.caption.53}}
\newlabel{tab:LogRegCls4-Wtp5}{{\M@TitleReference {3.48}{LogRegCls4-Wtp5\relax }}{18}{LogRegCls4-Wtp5\relax }{table.caption.53}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.49}{\ignorespaces LogRegCls4-Wt1p5: this won!\relax }}{18}{table.caption.54}}
\newlabel{tab:LogRegCls4-Wt1p5}{{\M@TitleReference {3.49}{LogRegCls4-Wt1p5: this won!\relax }}{18}{LogRegCls4-Wt1p5: this won!\relax }{table.caption.54}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.50}{\ignorespaces LogRegCls4-Wt2\relax }}{18}{table.caption.55}}
\newlabel{tab:LogRegCls4-Wt2}{{\M@TitleReference {3.50}{LogRegCls4-Wt2\relax }}{18}{LogRegCls4-Wt2\relax }{table.caption.55}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.8.5}Fine Tune Class 5 Weights}{18}{subsubsection.3.1.8.5}}
\@writefile{lot}{\contentsline {table}{\numberline {3.51}{\ignorespaces LogRegCls5-Wt1\relax }}{18}{table.caption.56}}
\newlabel{tab:LogRegCls5-Wt1}{{\M@TitleReference {3.51}{LogRegCls5-Wt1\relax }}{18}{LogRegCls5-Wt1\relax }{table.caption.56}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.52}{\ignorespaces LogRegCls5-Wtp5\relax }}{19}{table.caption.57}}
\newlabel{tab:LogRegCls5-Wtp5}{{\M@TitleReference {3.52}{LogRegCls5-Wtp5\relax }}{19}{LogRegCls5-Wtp5\relax }{table.caption.57}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.53}{\ignorespaces LogRegCls5-Wt1p5\relax }}{19}{table.caption.58}}
\newlabel{tab:LogRegCls5-Wt1p5}{{\M@TitleReference {3.53}{LogRegCls5-Wt1p5\relax }}{19}{LogRegCls5-Wt1p5\relax }{table.caption.58}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.54}{\ignorespaces LogRegCls5-Wt5\relax }}{19}{table.caption.59}}
\newlabel{tab:LogRegCls5-Wt5}{{\M@TitleReference {3.54}{LogRegCls5-Wt5\relax }}{19}{LogRegCls5-Wt5\relax }{table.caption.59}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.55}{\ignorespaces LogRegCls5-Wt10: this won!\relax }}{19}{table.caption.60}}
\newlabel{tab:LogRegCls5-Wt10}{{\M@TitleReference {3.55}{LogRegCls5-Wt10: this won!\relax }}{19}{LogRegCls5-Wt10: this won!\relax }{table.caption.60}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.56}{\ignorespaces LogRegCls5-Wt20\relax }}{19}{table.caption.61}}
\newlabel{tab:LogRegCls5-Wt20}{{\M@TitleReference {3.56}{LogRegCls5-Wt20\relax }}{19}{LogRegCls5-Wt20\relax }{table.caption.61}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.8.6}Fine Tune Class 6 Weights}{20}{subsubsection.3.1.8.6}}
\@writefile{lot}{\contentsline {table}{\numberline {3.57}{\ignorespaces LogRegCls6-Wt1\relax }}{20}{table.caption.62}}
\newlabel{tab:LogRegCls6-Wt1}{{\M@TitleReference {3.57}{LogRegCls6-Wt1\relax }}{20}{LogRegCls6-Wt1\relax }{table.caption.62}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.58}{\ignorespaces LogRegCls6-Wtp5\relax }}{20}{table.caption.63}}
\newlabel{tab:LogRegCls6-Wtp5}{{\M@TitleReference {3.58}{LogRegCls6-Wtp5\relax }}{20}{LogRegCls6-Wtp5\relax }{table.caption.63}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.59}{\ignorespaces LogRegCls6-Wt2: this wins!\relax }}{20}{table.caption.64}}
\newlabel{tab:LogRegCls6-Wt2}{{\M@TitleReference {3.59}{LogRegCls6-Wt2: this wins!\relax }}{20}{LogRegCls6-Wt2: this wins!\relax }{table.caption.64}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.60}{\ignorespaces LogRegCls6-Wt3\relax }}{20}{table.caption.65}}
\newlabel{tab:LogRegCls6-Wt3}{{\M@TitleReference {3.60}{LogRegCls6-Wt3\relax }}{20}{LogRegCls6-Wt3\relax }{table.caption.65}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.8.7}Fine Tune Class 7 Weights}{20}{subsubsection.3.1.8.7}}
\@writefile{lot}{\contentsline {table}{\numberline {3.61}{\ignorespaces LogRegCls7-Wt1\relax }}{20}{table.caption.66}}
\newlabel{tab:LogRegCls7-Wt1}{{\M@TitleReference {3.61}{LogRegCls7-Wt1\relax }}{20}{LogRegCls7-Wt1\relax }{table.caption.66}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.62}{\ignorespaces LogRegCls7-Wtp5\relax }}{21}{table.caption.67}}
\newlabel{tab:LogRegCls7-Wtp5}{{\M@TitleReference {3.62}{LogRegCls7-Wtp5\relax }}{21}{LogRegCls7-Wtp5\relax }{table.caption.67}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.63}{\ignorespaces LogRegCls7-Wt3: this won!\relax }}{21}{table.caption.68}}
\newlabel{tab:LogRegCls7-Wt3}{{\M@TitleReference {3.63}{LogRegCls7-Wt3: this won!\relax }}{21}{LogRegCls7-Wt3: this won!\relax }{table.caption.68}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.64}{\ignorespaces LogRegCls7-Wt5\relax }}{21}{table.caption.69}}
\newlabel{tab:LogRegCls7-Wt5}{{\M@TitleReference {3.64}{LogRegCls7-Wt5\relax }}{21}{LogRegCls7-Wt5\relax }{table.caption.69}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.8.8}Fine Tune Class 8 Weights}{21}{subsubsection.3.1.8.8}}
\@writefile{lot}{\contentsline {table}{\numberline {3.65}{\ignorespaces LogRegCls8-Wt1: this won!\relax }}{21}{table.caption.70}}
\newlabel{tab:LogRegCls8-Wt1}{{\M@TitleReference {3.65}{LogRegCls8-Wt1: this won!\relax }}{21}{LogRegCls8-Wt1: this won!\relax }{table.caption.70}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.66}{\ignorespaces LogRegCls8-Wtp5\relax }}{21}{table.caption.71}}
\newlabel{tab:LogRegCls8-Wtp5}{{\M@TitleReference {3.66}{LogRegCls8-Wtp5\relax }}{21}{LogRegCls8-Wtp5\relax }{table.caption.71}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.67}{\ignorespaces LogRegCls8-Wt1p5\relax }}{22}{table.caption.72}}
\newlabel{tab:LogRegCls8-Wt1p5}{{\M@TitleReference {3.67}{LogRegCls8-Wt1p5\relax }}{22}{LogRegCls8-Wt1p5\relax }{table.caption.72}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.9}Varied Logistic Regression Threshold}{22}{subsection.3.1.9}}
\@writefile{lot}{\contentsline {table}{\numberline {3.68}{\ignorespaces LogRegAftFineTune\relax }}{22}{table.caption.73}}
\newlabel{tab:LogRegAftFineTune}{{\M@TitleReference {3.68}{LogRegAftFineTune\relax }}{22}{LogRegAftFineTune\relax }{table.caption.73}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.69}{\ignorespaces LogRegOrig-0001\relax }}{22}{table.caption.74}}
\newlabel{tab:LogRegOrig-0001}{{\M@TitleReference {3.69}{LogRegOrig-0001\relax }}{22}{LogRegOrig-0001\relax }{table.caption.74}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.70}{\ignorespaces LogReg-00001 - this won!\relax }}{22}{table.caption.75}}
\newlabel{tab:LogReg-00001Redo}{{\M@TitleReference {3.70}{LogReg-00001 - this won!\relax }}{22}{LogReg-00001 - this won!\relax }{table.caption.75}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.71}{\ignorespaces LogReg-000001\relax }}{22}{table.caption.76}}
\newlabel{tab:LogReg-000001}{{\M@TitleReference {3.71}{LogReg-000001\relax }}{22}{LogReg-000001\relax }{table.caption.76}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.10}Varied Sample Weight On Test Set and Dropping Intermediate ROC Curve Values}{22}{subsection.3.1.10}}
\@writefile{lot}{\contentsline {table}{\numberline {3.72}{\ignorespaces LogReg-NoSW\relax }}{22}{table.caption.77}}
\newlabel{tab:LogReg-NoSW}{{\M@TitleReference {3.72}{LogReg-NoSW\relax }}{22}{LogReg-NoSW\relax }{table.caption.77}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.73}{\ignorespaces LogReg-DropFalse\relax }}{23}{table.caption.78}}
\newlabel{tab:LogReg-DropFalse}{{\M@TitleReference {3.73}{LogReg-DropFalse\relax }}{23}{LogReg-DropFalse\relax }{table.caption.78}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.74}{\ignorespaces LogReg-NoSW-DropFalse\relax }}{23}{table.caption.79}}
\newlabel{tab:LogReg-NoSW-DropFalse}{{\M@TitleReference {3.74}{LogReg-NoSW-DropFalse\relax }}{23}{LogReg-NoSW-DropFalse\relax }{table.caption.79}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.11}Varied Logistic Regression Positive Class Weight For Full Dataset}{23}{subsection.3.1.11}}
\@writefile{lot}{\contentsline {table}{\numberline {3.75}{\ignorespaces LogRegAllOrig-Wt20p887\relax }}{23}{table.caption.80}}
\newlabel{tab:LogRegAllOrig-Wt20p887}{{\M@TitleReference {3.75}{LogRegAllOrig-Wt20p887\relax }}{23}{LogRegAllOrig-Wt20p887\relax }{table.caption.80}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.76}{\ignorespaces LogRegAll-Wt23: this won!\relax }}{23}{table.caption.81}}
\newlabel{tab:LogRegAll-Wt23}{{\M@TitleReference {3.76}{LogRegAll-Wt23: this won!\relax }}{23}{LogRegAll-Wt23: this won!\relax }{table.caption.81}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.77}{\ignorespaces LogRegAll-Wt25\relax }}{23}{table.caption.82}}
\newlabel{tab:LogRegAll-Wt25}{{\M@TitleReference {3.77}{LogRegAll-Wt25\relax }}{23}{LogRegAll-Wt25\relax }{table.caption.82}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.12}Varied SVM Gamma}{23}{subsection.3.1.12}}
\@writefile{lot}{\contentsline {table}{\numberline {3.78}{\ignorespaces SVM-OrigWithFtune\relax }}{23}{table.caption.83}}
\newlabel{tab:SVM-OrigWithFtune}{{\M@TitleReference {3.78}{SVM-OrigWithFtune\relax }}{23}{SVM-OrigWithFtune\relax }{table.caption.83}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.79}{\ignorespaces SVM-C1-Gp0029674\relax }}{24}{table.caption.84}}
\newlabel{tab:SVM-C1-Gp0029674}{{\M@TitleReference {3.79}{SVM-C1-Gp0029674\relax }}{24}{SVM-C1-Gp0029674\relax }{table.caption.84}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.80}{\ignorespaces SVM-C2-Gp0029674\relax }}{24}{table.caption.85}}
\newlabel{tab:SVM-C2-Gp0029674}{{\M@TitleReference {3.80}{SVM-C2-Gp0029674\relax }}{24}{SVM-C2-Gp0029674\relax }{table.caption.85}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.81}{\ignorespaces SVM-Cp1-Gp0029674\relax }}{24}{table.caption.86}}
\newlabel{tab:SVM-Cp1-Gp0029674}{{\M@TitleReference {3.81}{SVM-Cp1-Gp0029674\relax }}{24}{SVM-Cp1-Gp0029674\relax }{table.caption.86}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.82}{\ignorespaces SVM-Cp05-Gp0029674\relax }}{24}{table.caption.87}}
\newlabel{tab:SVM-Cp05-Gp0029674}{{\M@TitleReference {3.82}{SVM-Cp05-Gp0029674\relax }}{24}{SVM-Cp05-Gp0029674\relax }{table.caption.87}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.83}{\ignorespaces SVM-Cp15-Gp0029674: this won!\relax }}{24}{table.caption.88}}
\newlabel{tab:SVM-Cp15-Gp0029674}{{\M@TitleReference {3.83}{SVM-Cp15-Gp0029674: this won!\relax }}{24}{SVM-Cp15-Gp0029674: this won!\relax }{table.caption.88}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.84}{\ignorespaces SVM-Cp2-Gp0029674\relax }}{24}{table.caption.89}}
\newlabel{tab:SVM-Cp2-Gp0029674}{{\M@TitleReference {3.84}{SVM-Cp2-Gp0029674\relax }}{24}{SVM-Cp2-Gp0029674\relax }{table.caption.89}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.13}Varied SVM Cost}{25}{subsection.3.1.13}}
\@writefile{lot}{\contentsline {table}{\numberline {3.85}{\ignorespaces SVM-Cp15-Gp002: this won!\relax }}{25}{table.caption.90}}
\newlabel{tab:SVM-Cp15-Gp002}{{\M@TitleReference {3.85}{SVM-Cp15-Gp002: this won!\relax }}{25}{SVM-Cp15-Gp002: this won!\relax }{table.caption.90}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.86}{\ignorespaces SVM-Cp15-Gp001\relax }}{25}{table.caption.91}}
\newlabel{tab:SVM-Cp15-Gp001}{{\M@TitleReference {3.86}{SVM-Cp15-Gp001\relax }}{25}{SVM-Cp15-Gp001\relax }{table.caption.91}{}}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {4}Results and Analysis}{26}{chapter.4}}
\newlabel{chap:aenied}{{\M@TitleReference {4}{Results and Analysis}}{26}{Results and Analysis}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Passive SVM Rbf kernel vs Logistic Reg}{26}{section.4.1}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Here are the results for the logistic regression passive 10 folds.\relax }}{26}{table.caption.92}}
\newlabel{tab:logReg}{{\M@TitleReference {4.1}{Here are the results for the logistic regression passive 10 folds.\relax }}{26}{Here are the results for the logistic regression passive 10 folds.\relax }{table.caption.92}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Here are the results for the logistic regression confusion matrices. The main source of the advantage for fine is from the decreased amount of false negatives.\relax }}{27}{table.caption.93}}
\newlabel{tab:logReg}{{\M@TitleReference {4.2}{Here are the results for the logistic regression confusion matrices. The main source of the advantage for fine is from the decreased amount of false negatives.\relax }}{27}{Here are the results for the logistic regression confusion matrices. The main source of the advantage for fine is from the decreased amount of false negatives.\relax }{table.caption.93}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces LogRegAll-Wt23\relax }}{27}{table.caption.94}}
\newlabel{tab:LogRegAll-Wt23}{{\M@TitleReference {4.3}{LogRegAll-Wt23\relax }}{27}{LogRegAll-Wt23\relax }{table.caption.94}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.4}{\ignorespaces Here are the results for the SVM passive 10 folds.\relax }}{27}{table.caption.95}}
\newlabel{tab:SVM}{{\M@TitleReference {4.4}{Here are the results for the SVM passive 10 folds.\relax }}{27}{Here are the results for the SVM passive 10 folds.\relax }{table.caption.95}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.5}{\ignorespaces Here are the results for the SVM confusion matrices. Here the fine returns less false negatives than the coarse, but not as many true positives compared to coarse.\relax }}{28}{table.caption.96}}
\newlabel{tab:SVM}{{\M@TitleReference {4.5}{Here are the results for the SVM confusion matrices. Here the fine returns less false negatives than the coarse, but not as many true positives compared to coarse.\relax }}{28}{Here are the results for the SVM confusion matrices. Here the fine returns less false negatives than the coarse, but not as many true positives compared to coarse.\relax }{table.caption.96}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.6}{\ignorespaces SVM-All\relax }}{28}{table.caption.97}}
\newlabel{tab:SVM-All}{{\M@TitleReference {4.6}{SVM-All\relax }}{28}{SVM-All\relax }{table.caption.97}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Fine has a higher accuracy than coarse at the default threshold.\relax }}{28}{figure.caption.98}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces The fine threshold occurs at a point on the pr-curve associated with a higher f-measure than the coarse curves.\relax }}{29}{figure.caption.99}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces SVM results are similar between coarse and fine.\relax }}{29}{figure.caption.100}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces SVM results for PR-curves and F-measure have coarse and fine picking different parts of the curves for their respective thresholds, coarse f1 avg is slightly higher at 0.468 compared to 0.457 for fine.\relax }}{30}{figure.caption.101}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Active vs Passive curves}{30}{section.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Plots for Logistic Regression Active vs Passive curves}{30}{subsection.4.2.1}}
\newlabel{fig:ActiveVsPassivePRLR}{{\M@TitleReference {\caption@xref {fig:ActiveVsPassivePRLR}{ on input line 1925}}{Plots for Logistic Regression Active vs Passive curves}}{31}{Plots for Logistic Regression Active vs Passive curves}{figure.caption.102}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces The PR AUC curves for rounds with the Logistic Regression classifier conforms to expectations, with active-fine having the highest performance. Active-coarse outperforms passive-coarse. Passive-fine doesn't outperform the coarse classifiers until rnd 100. \relax }}{31}{figure.caption.102}}
\newlabel{fig:ActiveVsPassiveROCLR}{{\M@TitleReference {\caption@xref {fig:ActiveVsPassiveROCLR}{ on input line 1937}}{Plots for Logistic Regression Active vs Passive curves}}{32}{Plots for Logistic Regression Active vs Passive curves}{figure.caption.103}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces The ROC AUC curves for rounds with the Logistic Regression classifier. The active curves beat out the passive curves for both coarse and fine. Coarse roc starts with an advantage over fine as in the PR curves. Both converge to the same rate after roc auc level after 80.\relax }}{32}{figure.caption.103}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Plots for SVM Active vs Passive curves}{33}{subsection.4.2.2}}
\newlabel{fig:ActiveVsPassivePRSVM}{{\M@TitleReference {\caption@xref {fig:ActiveVsPassivePRSVM}{ on input line 1982}}{Plots for SVM Active vs Passive curves}}{33}{Plots for SVM Active vs Passive curves}{figure.caption.104}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces The PR AUC curves for rounds with SVM show little advantage for fine. The results are slightly different than the ones shown on 2/14 due to fixing a bug with the code that wasn't performing the preprocessing scaling for the SVM case at the same stage as it was being done for the logistic regression classifier.\relax }}{33}{figure.caption.104}}
\newlabel{fig:ActiveVsPassiveROCSVM}{{\M@TitleReference {\caption@xref {fig:ActiveVsPassiveROCSVM}{ on input line 1995}}{Plots for SVM Active vs Passive curves}}{34}{Plots for SVM Active vs Passive curves}{figure.caption.105}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces The ROC curves show more of an advantage for coarse classifiers.\relax }}{34}{figure.caption.105}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Plots for FFR experiments}{34}{section.4.3}}
\newlabel{fig:FFR_PR_Cost1}{{\M@TitleReference {\caption@xref {fig:FFR_PR_Cost1}{ on input line 2032}}{Plots for FFR experiments}}{35}{Plots for FFR experiments}{figure.caption.106}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces The strategy is changed from purchasing a set number of instances per round to having a set budget per round and spending a portion of that budget on fine and coarse grained labels. For this curve the fine and coarse grain labels both have a cost of 1. The purple 1.0 curve shows that if only fine grained labels are purchased, the highest performing PR-AUC can be obtained. The results are an average of 10 folds.\relax }}{35}{figure.caption.106}}
\newlabel{fig:FFR_PR_Cost16_rnds0_171}{{\M@TitleReference {\caption@xref {fig:FFR_PR_Cost16_rnds0_171}{ on input line 2046}}{Plots for FFR experiments}}{36}{Plots for FFR experiments}{figure.caption.107}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces The fine cost is increased to 16. The budget for each iteration is 100, and for the case of the 0.5 curve, 50 instances are bought for coarse and 3.125 instances are bought for fine. The remainder 0.125 is then turned into a 0.125 chance for any round to purchase an extra fine label. The round size for the FFR 1.0 curve is very small, with only 7 labels purchased per iteration. The cost is to high for the fine label advantage to offset the decreased number of instances purchased.\relax }}{36}{figure.caption.107}}
\newlabel{fig:FFR_PR_Cost16_rnds0_500}{{\M@TitleReference {\caption@xref {fig:FFR_PR_Cost16_rnds0_500}{ on input line 2061}}{Plots for FFR experiments}}{37}{Plots for FFR experiments}{figure.caption.108}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces This shows the iterations continuing through round 500, the curves with the higher fine rates eventually settle to the same end point that the curves with the high rates of coarse labels purchased achieved at previous iterations.\relax }}{37}{figure.caption.108}}
\newlabel{fig:FFR_PR_Cost8_rnds0_171}{{\M@TitleReference {\caption@xref {fig:FFR_PR_Cost8_rnds0_171}{ on input line 2075}}{Plots for FFR experiments}}{38}{Plots for FFR experiments}{figure.caption.109}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.12}{\ignorespaces At fine cost 8 the FFR 0.0 rate is no longer the best option, 0.1 generally outperforms 0.0 slightly.\relax }}{38}{figure.caption.109}}
\newlabel{fig:FFR_PR_Cost8_rnds0_500}{{\M@TitleReference {\caption@xref {fig:FFR_PR_Cost8_rnds0_500}{ on input line 2086}}{Plots for FFR experiments}}{39}{Plots for FFR experiments}{figure.caption.110}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.13}{\ignorespaces The extended picture of the FFR cost 8. The round size for FFR 1.0 is small, only 13 instances purchase per iteration.\relax }}{39}{figure.caption.110}}
\newlabel{fig:FFR_PR_Cost4_rnds0_171}{{\M@TitleReference {\caption@xref {fig:FFR_PR_Cost4_rnds0_171}{ on input line 2097}}{Plots for FFR experiments}}{40}{Plots for FFR experiments}{figure.caption.111}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.14}{\ignorespaces At fine cost 4, FFR 0.3 appears to be the highest performing rate.\relax }}{40}{figure.caption.111}}
\newlabel{fig:FFR_PR_Cost4_rnds20_60}{{\M@TitleReference {\caption@xref {fig:FFR_PR_Cost4_rnds20_60}{ on input line 2107}}{Plots for FFR experiments}}{41}{Plots for FFR experiments}{figure.caption.112}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.15}{\ignorespaces The fine cost 4 curves shown expanding the rounds 20-60.\relax }}{41}{figure.caption.112}}
\newlabel{fig:FFR_PR_Cost2_rnds0_171}{{\M@TitleReference {\caption@xref {fig:FFR_PR_Cost2_rnds0_171}{ on input line 2117}}{Plots for FFR experiments}}{42}{Plots for FFR experiments}{figure.caption.113}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.16}{\ignorespaces At fine cost 2, the preferred rate jumps up to 0.8, similar to the cost 1 results.\relax }}{42}{figure.caption.113}}
\newlabel{fig:FFR_PR_Cost2_rnds20_60}{{\M@TitleReference {\caption@xref {fig:FFR_PR_Cost2_rnds20_60}{ on input line 2127}}{Plots for FFR experiments}}{43}{Plots for FFR experiments}{figure.caption.114}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.17}{\ignorespaces The fine cost 2 curves shown expanding rounds 20-60.\relax }}{43}{figure.caption.114}}
\bibstyle{IEEEtran}
\bibdata{IEEEabrv,nuthesis}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {5}Conclusions and Future Work}{44}{chapter.5}}
\newlabel{chap:math}{{\M@TitleReference {5}{Conclusions and Future Work}}{44}{Conclusions and Future Work}{chapter.5}{}}
\bibcite{mitchell}{1}
\bibcite{scikit-learn}{2}
\bibcite{lsu-lsal-13}{3}
\bibcite{Dasgupta2008}{4}
\bibcite{Merialdo2001}{5}
\bibcite{Ling2012fine}{6}
\bibcite{sklearn-api}{7}
\citation{*}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{45}{section*.116}}
\memsetcounter{lastsheet}{51}
\memsetcounter{lastpage}{45}
