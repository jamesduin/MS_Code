Many classification tasks target high-level concepts that can be decomposed into a hierarchy of finer-grained subconcepts.  For example, some string entities that are Locations are also Attractions, some Attractions are Museums, and so on.  Such hierarchies are common in named entity recognition (NER), document classification, and biological sequence analysis.  We present a new approach for learning hierarchically decomposable concepts.  The approach learns a high-level classifier (e.g., location versus non-location) by separately learning multiple finer-grained classifiers (e.g., museum versus non-museum), and then combining the results.  Soliciting labels at a finer level of granularity than that of the target concept is a new approach to active learning, which we term "active over-labeling." We show that simple methods for active over-labeling can improve performance, in terms of theoretical guarantees and empirical results.  In experiments in NER and document classification tasks, we show that active over-labeling substantially improves area under the precision-recall curve, when compared with standard passive or active learning.
